{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Kaggle Q&A LightGBM.ipynb",
      "provenance": [],
      "mount_file_id": "1oW0B63K_IN-u4906Kz-zZVZ0AgOHUXl1",
      "authorship_tag": "ABX9TyO/2/hXS1w6rkTqJSWetNyW",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/bob123kk/NLP-Question-Answering/blob/master/Kaggle_Q%26A_LightGBM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kQPb8T0i2IMz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2c0f3efa-1650-4e72-858c-dbbfb16eb96d"
      },
      "source": [
        "!pip install python-Levenshtein\n",
        "!pip install contractions\n",
        "!pip install fuzzywuzzy"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting python-Levenshtein\n",
            "  Downloading python-Levenshtein-0.12.2.tar.gz (50 kB)\n",
            "\u001b[?25l\r\u001b[K     |██████▌                         | 10 kB 21.6 MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 20 kB 28.4 MB/s eta 0:00:01\r\u001b[K     |███████████████████▌            | 30 kB 23.5 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 40 kB 18.6 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 50 kB 3.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from python-Levenshtein) (57.2.0)\n",
            "Building wheels for collected packages: python-Levenshtein\n",
            "  Building wheel for python-Levenshtein (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for python-Levenshtein: filename=python_Levenshtein-0.12.2-cp37-cp37m-linux_x86_64.whl size=149871 sha256=a45e6c372fecd0df36898b1bac90018fc635db11bf7745099a1e0b38e9340cc8\n",
            "  Stored in directory: /root/.cache/pip/wheels/05/5f/ca/7c4367734892581bb5ff896f15027a932c551080b2abd3e00d\n",
            "Successfully built python-Levenshtein\n",
            "Installing collected packages: python-Levenshtein\n",
            "Successfully installed python-Levenshtein-0.12.2\n",
            "Collecting contractions\n",
            "  Downloading contractions-0.0.52-py2.py3-none-any.whl (7.2 kB)\n",
            "Collecting textsearch>=0.0.21\n",
            "  Downloading textsearch-0.0.21-py2.py3-none-any.whl (7.5 kB)\n",
            "Collecting anyascii\n",
            "  Downloading anyascii-0.2.0-py3-none-any.whl (283 kB)\n",
            "\u001b[K     |████████████████████████████████| 283 kB 8.8 MB/s \n",
            "\u001b[?25hCollecting pyahocorasick\n",
            "  Downloading pyahocorasick-1.4.2.tar.gz (321 kB)\n",
            "\u001b[K     |████████████████████████████████| 321 kB 48.0 MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: pyahocorasick\n",
            "  Building wheel for pyahocorasick (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyahocorasick: filename=pyahocorasick-1.4.2-cp37-cp37m-linux_x86_64.whl size=85452 sha256=428b810d1bc4624fb082428834f635683a87b530baf5c000c6c4d590b1e6ebef\n",
            "  Stored in directory: /root/.cache/pip/wheels/25/19/a6/8f363d9939162782bb8439d886469756271abc01f76fbd790f\n",
            "Successfully built pyahocorasick\n",
            "Installing collected packages: pyahocorasick, anyascii, textsearch, contractions\n",
            "Successfully installed anyascii-0.2.0 contractions-0.0.52 pyahocorasick-1.4.2 textsearch-0.0.21\n",
            "Collecting fuzzywuzzy\n",
            "  Downloading fuzzywuzzy-0.18.0-py2.py3-none-any.whl (18 kB)\n",
            "Installing collected packages: fuzzywuzzy\n",
            "Successfully installed fuzzywuzzy-0.18.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d-l6A_Ge2VwN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d212456b-e236-42d7-c40b-dfde99d34a53"
      },
      "source": [
        "import os\n",
        "import gc\n",
        "import json\n",
        "import numpy as np \n",
        "import pandas as pd\n",
        "import pickle\n",
        "import re\n",
        "import Levenshtein\n",
        "import unicodedata\n",
        "import lightgbm as lgb\n",
        "import contractions\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm.notebook import tqdm\n",
        "from bs4 import BeautifulSoup\n",
        "from fuzzywuzzy import fuzz\n",
        "from scipy import spatial\n",
        "from sklearn.feature_extraction import text\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.model_selection import GroupKFold\n",
        "from imblearn.under_sampling import RandomUnderSampler\n",
        "from imblearn.over_sampling import RandomOverSampler       \n",
        "from sklearn.metrics import accuracy_score,recall_score, f1_score,confusion_matrix\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/externals/six.py:31: FutureWarning: The module is deprecated in version 0.21 and will be removed in version 0.23 since we've dropped support for Python 2.7. Please rely on the official version of six (https://pypi.org/project/six/).\n",
            "  \"(https://pypi.org/project/six/).\", FutureWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/deprecation.py:144: FutureWarning: The sklearn.neighbors.base module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.neighbors. Anything that cannot be imported from sklearn.neighbors is now part of the private API.\n",
            "  warnings.warn(message, FutureWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SuweTgl_qPuL"
      },
      "source": [
        "import numpy"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JtjsQrrbpvHd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "26177e20-dc86-4b6f-a105-bc04d3393da3"
      },
      "source": [
        "print(numpy.__version__)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.19.5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AT5t4IG_3XsR"
      },
      "source": [
        "### helper Function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xVlxzKjw3V1g"
      },
      "source": [
        "def read_data(path, size):\n",
        "    df = []\n",
        "    with open(path, 'rt') as reader:\n",
        "      for i in range(size):\n",
        "        df.append(json.loads(reader.readline()))\n",
        "        df_train = pd.DataFrame(df)\n",
        "\n",
        "    return df_train"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JHy5E9CU2tzR"
      },
      "source": [
        "train_data_path='/content/drive/My Drive/Q&A Data/tensorflow2-question-answering/simplified-nq-train.jsonl'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fy0YjrIW8Iza",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 379
        },
        "outputId": "dea300d4-b64a-43be-e682-cb454bf6fcfe"
      },
      "source": [
        "read_train = read_data(train_data_path,100)\n",
        "read_train.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>document_text</th>\n",
              "      <th>long_answer_candidates</th>\n",
              "      <th>question_text</th>\n",
              "      <th>annotations</th>\n",
              "      <th>document_url</th>\n",
              "      <th>example_id</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Email marketing - Wikipedia &lt;H1&gt; Email marketi...</td>\n",
              "      <td>[{'start_token': 14, 'top_level': True, 'end_t...</td>\n",
              "      <td>which is the most common use of opt-in e-mail ...</td>\n",
              "      <td>[{'yes_no_answer': 'NONE', 'long_answer': {'st...</td>\n",
              "      <td>https://en.wikipedia.org//w/index.php?title=Em...</td>\n",
              "      <td>5655493461695504401</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>The Mother ( How I Met Your Mother ) - wikiped...</td>\n",
              "      <td>[{'start_token': 28, 'top_level': True, 'end_t...</td>\n",
              "      <td>how i.met your mother who is the mother</td>\n",
              "      <td>[{'yes_no_answer': 'NONE', 'long_answer': {'st...</td>\n",
              "      <td>https://en.wikipedia.org//w/index.php?title=Th...</td>\n",
              "      <td>5328212470870865242</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Human fertilization - wikipedia &lt;H1&gt; Human fer...</td>\n",
              "      <td>[{'start_token': 14, 'top_level': True, 'end_t...</td>\n",
              "      <td>what type of fertilisation takes place in humans</td>\n",
              "      <td>[{'yes_no_answer': 'NONE', 'long_answer': {'st...</td>\n",
              "      <td>https://en.wikipedia.org//w/index.php?title=Hu...</td>\n",
              "      <td>4435104480114867852</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>List of National Football League career quarte...</td>\n",
              "      <td>[{'start_token': 28, 'top_level': True, 'end_t...</td>\n",
              "      <td>who had the most wins in the nfl</td>\n",
              "      <td>[{'yes_no_answer': 'NONE', 'long_answer': {'st...</td>\n",
              "      <td>https://en.wikipedia.org//w/index.php?title=Li...</td>\n",
              "      <td>5289242154789678439</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Roanoke Colony - wikipedia &lt;H1&gt; Roanoke Colony...</td>\n",
              "      <td>[{'start_token': 32, 'top_level': True, 'end_t...</td>\n",
              "      <td>what happened to the lost settlement of roanoke</td>\n",
              "      <td>[{'yes_no_answer': 'NONE', 'long_answer': {'st...</td>\n",
              "      <td>https://en.wikipedia.org//w/index.php?title=Ro...</td>\n",
              "      <td>5489863933082811018</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                       document_text  ...           example_id\n",
              "0  Email marketing - Wikipedia <H1> Email marketi...  ...  5655493461695504401\n",
              "1  The Mother ( How I Met Your Mother ) - wikiped...  ...  5328212470870865242\n",
              "2  Human fertilization - wikipedia <H1> Human fer...  ...  4435104480114867852\n",
              "3  List of National Football League career quarte...  ...  5289242154789678439\n",
              "4  Roanoke Colony - wikipedia <H1> Roanoke Colony...  ...  5489863933082811018\n",
              "\n",
              "[5 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I1LWtgSWNkt8"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "df_train, df_valid=  train_test_split(read_train, test_size=0.33, random_state=42)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kdzyT6hwN0Ln",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "02f07994-55a6-4d9d-8999-4680a8d84b21"
      },
      "source": [
        "print('df_train shape: ', df_train.shape)\n",
        "print('df_valid shape: ', df_valid.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "df_train shape:  (67, 6)\n",
            "df_valid shape:  (33, 6)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U5f6ahit8KtS"
      },
      "source": [
        "\n",
        "def unstack_datafram(df_train=df_train):\n",
        "    ids = []\n",
        "    doc = []\n",
        "    targets = []\n",
        "    questions = []\n",
        "    Q_tfidf = []\n",
        "    candidate_string = []\n",
        "    C_tfidf = []\n",
        "    features = []\n",
        "\n",
        "    for index, row in df_train.iterrows():\n",
        "    \n",
        "        # process document text\n",
        "        doc_text = row['document_text']\n",
        "        tfidf = TfidfVectorizer()#stop_words=text.ENGLISH_STOP_WORDS)\n",
        "        tfidf.fit([doc_text])\n",
        "        \n",
        "        question_tfidf = tfidf.transform([row['question_text']]).todense()\n",
        "\n",
        "        start_token_true = row['annotations'][0]['long_answer']['start_token']\n",
        "        end_token_true = row['annotations'][0]['long_answer']['end_token']\n",
        "\n",
        "        # Tokenized doc text\n",
        "        doc_tokenized = row['document_text'].split(' ')\n",
        "        \n",
        "        candidates = row['long_answer_candidates']\n",
        "        # remove nested candidates\n",
        "        candidates = [c for c in candidates if c['top_level'] == True]\n",
        "\n",
        "        if start_token_true != -1:\n",
        "            for c in candidates:\n",
        "              ids.append(str(row['example_id']))\n",
        "              doc.append([doc_text])\n",
        "              \n",
        "              questions.append(row['question_text'])\n",
        "              Q_tfidf.append(question_tfidf)\n",
        "              start_token = c['start_token']\n",
        "              end_token = c['end_token']\n",
        "              candidate = ' '.join(doc_tokenized[start_token:end_token])\n",
        "              candidate_string.append(candidate)\n",
        "              candidate_tfidf = tfidf.transform([candidate]).todense()\n",
        "              C_tfidf.append(candidate_tfidf)\n",
        "\n",
        "              #extract_features\n",
        "\n",
        "              token_sort_ratio = fuzz.token_sort_ratio(str(row['question_text']), str(candidate))\n",
        "              token_set_ratio = fuzz.token_set_ratio(str(row['question_text']), str(candidate))\n",
        "\n",
        "              cos_d = spatial.distance.cosine(question_tfidf, candidate_tfidf)\n",
        "              euc_d = np.linalg.norm(question_tfidf - candidate_tfidf)\n",
        "              lev_d = Levenshtein.distance(row['question_text'], candidate)\n",
        "              lev_r = Levenshtein.ratio(row['question_text'], candidate)\n",
        "              jar_s = Levenshtein.jaro(row['question_text'], candidate)\n",
        "              jaw_s = Levenshtein.jaro_winkler(row['question_text'], candidate)\n",
        "              tfidf_score = np.sum(question_tfidf*candidate_tfidf.T)\n",
        "              question_tfidf_sum = np.sum(question_tfidf)\n",
        "              answer_tfidf_sum = np.sum(candidate_tfidf)\n",
        "\n",
        "              features.append([\n",
        "              token_sort_ratio,\n",
        "              token_set_ratio,\n",
        "              cos_d,\n",
        "              euc_d,\n",
        "              lev_d,\n",
        "              lev_r,\n",
        "              jar_s,\n",
        "              jaw_s,\n",
        "              tfidf_score,  \n",
        "              question_tfidf_sum,\n",
        "              answer_tfidf_sum,         \n",
        "              ])\n",
        "\n",
        "              if start_token == start_token_true and end_token == end_token_true:\n",
        "                target = 1\n",
        "              else:\n",
        "                target = 0\n",
        "\n",
        "              targets.append(target)\n",
        "\n",
        "\n",
        "    train = pd.DataFrame()\n",
        "    train['example_id'] = ids\n",
        "    train['document'] = doc\n",
        "    train['question'] = questions\n",
        "    train['Q_tfidf'] = Q_tfidf\n",
        "    train['candidate'] = candidate_string\n",
        "    train['C_tfidf'] = C_tfidf\n",
        "    train['target'] = targets\n",
        "\n",
        "    features = np.array(features)\n",
        "    features_df = pd.DataFrame(features)\n",
        "    features_df.columns = ['token_sort_ratio',\n",
        "                          'token_set_ratio', \n",
        "                          'cos_d','euc_d',\n",
        "                          'lev_d','lev_r',\n",
        "                          'jar_s','jaw_s',\n",
        "                          'tfidf_score', \n",
        "                          'question_tfidf_sum',\n",
        "                          'answer_tfidf_sum'  ]\n",
        "    train = pd.concat([train, features_df], axis=1)\n",
        "\n",
        "    return train\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mhpOLgSXRMY2"
      },
      "source": [
        "valid = unstack_datafram(df_valid)\n",
        "train = unstack_datafram(df_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nzVWLWBXe2Wp",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        },
        "outputId": "69fc9fac-d24b-4fe7-d493-d95a09ca1ec6"
      },
      "source": [
        "train.head(1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>example_id</th>\n",
              "      <th>document</th>\n",
              "      <th>question</th>\n",
              "      <th>Q_tfidf</th>\n",
              "      <th>candidate</th>\n",
              "      <th>C_tfidf</th>\n",
              "      <th>target</th>\n",
              "      <th>token_sort_ratio</th>\n",
              "      <th>token_set_ratio</th>\n",
              "      <th>cos_d</th>\n",
              "      <th>euc_d</th>\n",
              "      <th>lev_d</th>\n",
              "      <th>lev_r</th>\n",
              "      <th>jar_s</th>\n",
              "      <th>jaw_s</th>\n",
              "      <th>tfidf_score</th>\n",
              "      <th>question_tfidf_sum</th>\n",
              "      <th>answer_tfidf_sum</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>-6638952910263008958</td>\n",
              "      <td>[Life or Something Like it - wikipedia &lt;H1&gt; Li...</td>\n",
              "      <td>where was life or something like it filmed</td>\n",
              "      <td>[[[[[0.         0.         0.         0.      ...</td>\n",
              "      <td>&lt;Table&gt; &lt;Tr&gt; &lt;Th_colspan=\"2\"&gt; Life or Somethin...</td>\n",
              "      <td>[[[[[0.         0.         0.         0.      ...</td>\n",
              "      <td>0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>75.0</td>\n",
              "      <td>0.966639</td>\n",
              "      <td>1.390424</td>\n",
              "      <td>1094.0</td>\n",
              "      <td>0.063086</td>\n",
              "      <td>0.432588</td>\n",
              "      <td>0.432588</td>\n",
              "      <td>0.033361</td>\n",
              "      <td>2.645751</td>\n",
              "      <td>3.230474</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "             example_id  ... answer_tfidf_sum\n",
              "0  -6638952910263008958  ...         3.230474\n",
              "\n",
              "[1 rows x 18 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kkt6gMq6L18t"
      },
      "source": [
        "### Feature Engineering"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QYf2RoXsPrl4"
      },
      "source": [
        "# Tokenizing & Cleaning  Q-A pairs \n",
        "\n",
        "from gensim.parsing.preprocessing import preprocess_string,strip_punctuation, \\\n",
        "remove_stopwords,strip_numeric,strip_punctuation\n",
        "\n",
        "def get_tokenized(data='train'):\n",
        "  if data =='train':\n",
        "    X = train\n",
        "  else:\n",
        "    X = valid\n",
        "  \n",
        "  series = pd.Series(pd.concat([X['question'],X['candidate']]), dtype=str) \n",
        "  series.dropna()\n",
        "  for row in series:\n",
        "    \n",
        "    yield row.split(' ')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aJ2jPPGOEUB_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "725c1b94-3914-45e5-89c0-6adf4cd79f42"
      },
      "source": [
        "token_train = [x for x in get_tokenized('train')]\n",
        "# token_test = [x for x in get_tokenized('test')]\n",
        "token_train[0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['where', 'was', 'life', 'or', 'something', 'like', 'it', 'filmed']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bLtLkiUnUX7M"
      },
      "source": [
        "### Word Embedding"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uy0GLRWqQmbh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a7313d64-8fa9-492d-d887-f6a6a364c97b"
      },
      "source": [
        "from gensim.models import Word2Vec\n",
        "\n",
        "# building a word2vec neural network on training set\n",
        "model_w2v = Word2Vec(token_train,size = 300)\n",
        "Word_model_path = '/content/drive/My Drive/Word2vec/GoogleNews.bin'\n",
        "model_w2v.intersect_word2vec_format(Word_model_path,\n",
        "                                    lockf=1.0,\n",
        "                                    binary=True)\n",
        "# training a word2vec neural network\n",
        "model_w2v.train(token_train, total_examples=model_w2v.corpus_count, epochs=10)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(931803, 1622740)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_1Zj8iW2TpSf"
      },
      "source": [
        "def get_token_has_vectors(model,data):\n",
        "  for row in get_tokenized(data):\n",
        "    tf_idf_tokens = []  \n",
        "    for token in row:\n",
        "      try:\n",
        "        vector = model.wv[token]\n",
        "        \n",
        "        tf_idf_tokens.append(token)\n",
        "      except:\n",
        "        continue\n",
        "\n",
        "    yield np.array(tf_idf_tokens)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CsOWbUgJdqkQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e42954c6-4799-4eec-832c-139a8af663cb"
      },
      "source": [
        "token_valid_vec = [x for x in get_token_has_vectors(model_w2v,'train')]\n",
        "token_valid_vec[0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['where', 'was', 'life', 'or', 'something', 'like', 'it', 'filmed'],\n",
              "      dtype='<U9')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QewiLisLT3ED",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dc7044cc-c7a4-4b43-9b80-158db3b7346f"
      },
      "source": [
        "print('number of Q-A pairs: ',len(token_valid_vec)/2 )"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "number of Q-A pairs:  1156.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_PjvUphNUJ56"
      },
      "source": [
        "# For valid tokens, find tfidf weights\n",
        "\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "pass_through = lambda x:x\n",
        "tfidf_QA = TfidfVectorizer(analyzer=pass_through)\n",
        "# caculating TF_IDF weights for tokens having valid w2v vectors\n",
        "X_trfmd = tfidf_QA.fit_transform(token_valid_vec)\n",
        "# split into Questions and Answers weights\n",
        "Q_trfmd = X_trfmd[:len(train)]\n",
        "A_trfmd = X_trfmd[len(train):]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0j9DYMOo87ti"
      },
      "source": [
        "token_valid_vec = [x for x in get_token_has_vectors(model_w2v,'train')]\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NA3rcxAVUnoS"
      },
      "source": [
        "def get_tfidf_weights_and_wv(tfidf_matrix,tfidf_vec,model_w2v):\n",
        "  w2v = []\n",
        "  tfidf_weights = []\n",
        "  row_records = tfidf_matrix.shape[0]\n",
        "  vocab_dict = {id:word for word, id in tfidf_vec.vocabulary_.items()}\n",
        "  # ct=0\n",
        "  for row in range(row_records):\n",
        "\n",
        "    word_id = tfidf_matrix[row,:].nonzero()[1]\n",
        "\n",
        "    tfidf_weights.append([tfidf_matrix[row,id] for id in word_id])\n",
        "    \n",
        "    w2v.append([model_w2v.wv[vocab_dict[id]] for id in word_id])\n",
        "\n",
        "  return np.array(tfidf_weights),np.array(w2v)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5NS1yxPgU9eR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f38d929e-0107-40a2-8d13-9675065777ec"
      },
      "source": [
        "Q_tfidf_weights,Q_w2v = get_tfidf_weights_and_wv(Q_trfmd,tfidf_QA,model_w2v)\n",
        "A_tfidf_weights,A_w2v = get_tfidf_weights_and_wv(A_trfmd,tfidf_QA,model_w2v)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:15: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "  from ipykernel import kernelapp as app\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M6u-JV6EVBeZ"
      },
      "source": [
        "from sklearn.metrics import pairwise_distances\n",
        "def compute(wv_Q,wv_A,weight_Q,weight_A,method):\n",
        "  temp = []\n",
        "  c = 1\n",
        "  for row in zip(wv_Q,wv_A,weight_Q,weight_A):\n",
        "\n",
        "    if row:\n",
        "      Q_v,A_v,Q_w,A_w = row\n",
        "      \n",
        "      Q_w =np.array(Q_w).reshape(-1,1)\n",
        "      A_w =np.array(A_w).reshape(-1,1)\n",
        "\n",
        "      dist = pairwise_distances(Q_v,A_v,metric=method)\n",
        "      weights = np.matmul(Q_w,A_w.T)\n",
        "      \n",
        "      weighted_avg = np.average(dist,weights=weights)\n",
        "      temp.append(weighted_avg)\n",
        "      # print('{} :'.format(c),weighted_avg)\n",
        "    else:\n",
        "      temp.append(np.nan)\n",
        "    c+=1\n",
        "  return temp"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GXhT3yM6VNi4"
      },
      "source": [
        "Q = Q_w2v\n",
        "A = A_w2v\n",
        "Q_w = Q_tfidf_weights\n",
        "A_w = A_tfidf_weights\n",
        "methods = ['euclidean','cosine','chebyshev','correlation']\n",
        "\n",
        "def get_distance_features(Q,A,Q_w,A_w):\n",
        "  features = []\n",
        "  for method in methods:\n",
        "    feature = compute(Q,A,Q_w,A_w,method)\n",
        "    \n",
        "    features.append(feature)\n",
        "  \n",
        "  features = np.array(features).T \n",
        "  features_df = pd.DataFrame(features)\n",
        "  features_df.columns = methods\n",
        "\n",
        "\n",
        "  return features_df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KzPDFVRWVPgY"
      },
      "source": [
        "features_df = get_distance_features(Q,A,Q_w,A_w)\n",
        "train = pd.concat([train, features_df], axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FxS4_EHzVSwh",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 371
        },
        "outputId": "ae5a7cb3-782f-4739-c392-2360b993dab5"
      },
      "source": [
        "train[:3]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>example_id</th>\n",
              "      <th>document</th>\n",
              "      <th>question</th>\n",
              "      <th>Q_tfidf</th>\n",
              "      <th>candidate</th>\n",
              "      <th>C_tfidf</th>\n",
              "      <th>target</th>\n",
              "      <th>token_sort_ratio</th>\n",
              "      <th>token_set_ratio</th>\n",
              "      <th>cos_d</th>\n",
              "      <th>euc_d</th>\n",
              "      <th>lev_d</th>\n",
              "      <th>lev_r</th>\n",
              "      <th>jar_s</th>\n",
              "      <th>jaw_s</th>\n",
              "      <th>tfidf_score</th>\n",
              "      <th>question_tfidf_sum</th>\n",
              "      <th>answer_tfidf_sum</th>\n",
              "      <th>euclidean</th>\n",
              "      <th>cosine</th>\n",
              "      <th>chebyshev</th>\n",
              "      <th>correlation</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>-6638952910263008958</td>\n",
              "      <td>[Life or Something Like it - wikipedia &lt;H1&gt; Li...</td>\n",
              "      <td>where was life or something like it filmed</td>\n",
              "      <td>[[[[[0.         0.         0.         0.      ...</td>\n",
              "      <td>&lt;Table&gt; &lt;Tr&gt; &lt;Th_colspan=\"2\"&gt; Life or Somethin...</td>\n",
              "      <td>[[[[[0.         0.         0.         0.      ...</td>\n",
              "      <td>0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>75.0</td>\n",
              "      <td>0.966639</td>\n",
              "      <td>1.390424</td>\n",
              "      <td>1094.0</td>\n",
              "      <td>0.063086</td>\n",
              "      <td>0.432588</td>\n",
              "      <td>0.432588</td>\n",
              "      <td>0.033361</td>\n",
              "      <td>2.645751</td>\n",
              "      <td>3.230474</td>\n",
              "      <td>11.816193</td>\n",
              "      <td>0.983654</td>\n",
              "      <td>2.066756</td>\n",
              "      <td>0.983616</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>-6638952910263008958</td>\n",
              "      <td>[Life or Something Like it - wikipedia &lt;H1&gt; Li...</td>\n",
              "      <td>where was life or something like it filmed</td>\n",
              "      <td>[[[[[0.         0.         0.         0.      ...</td>\n",
              "      <td>&lt;P&gt; Life or Something Like It is a 2002 romant...</td>\n",
              "      <td>[[[[[0.         0.         0.         0.      ...</td>\n",
              "      <td>0</td>\n",
              "      <td>20.0</td>\n",
              "      <td>82.0</td>\n",
              "      <td>0.686455</td>\n",
              "      <td>1.171713</td>\n",
              "      <td>352.0</td>\n",
              "      <td>0.163170</td>\n",
              "      <td>0.441713</td>\n",
              "      <td>0.441713</td>\n",
              "      <td>0.313545</td>\n",
              "      <td>2.645751</td>\n",
              "      <td>6.532796</td>\n",
              "      <td>8.208655</td>\n",
              "      <td>0.774301</td>\n",
              "      <td>1.438670</td>\n",
              "      <td>0.773688</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>-6638952910263008958</td>\n",
              "      <td>[Life or Something Like it - wikipedia &lt;H1&gt; Li...</td>\n",
              "      <td>where was life or something like it filmed</td>\n",
              "      <td>[[[[[0.         0.         0.         0.      ...</td>\n",
              "      <td>&lt;P&gt; Lanie Kerrigan ( Angelina Jolie ) , a succ...</td>\n",
              "      <td>[[[[[0.         0.06189845 0.         0.      ...</td>\n",
              "      <td>0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>29.0</td>\n",
              "      <td>0.883023</td>\n",
              "      <td>1.328927</td>\n",
              "      <td>821.0</td>\n",
              "      <td>0.090708</td>\n",
              "      <td>0.434603</td>\n",
              "      <td>0.434603</td>\n",
              "      <td>0.116977</td>\n",
              "      <td>2.645751</td>\n",
              "      <td>8.480087</td>\n",
              "      <td>7.601752</td>\n",
              "      <td>0.739477</td>\n",
              "      <td>1.347625</td>\n",
              "      <td>0.738863</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "             example_id  ... correlation\n",
              "0  -6638952910263008958  ...    0.983616\n",
              "1  -6638952910263008958  ...    0.773688\n",
              "2  -6638952910263008958  ...    0.738863\n",
              "\n",
              "[3 rows x 22 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2hKzyiTWxO2N"
      },
      "source": [
        "### Training Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZWJ1Ry4uWQI-"
      },
      "source": [
        "cols_to_drop = ['example_id','document', 'Q_tfidf','C_tfidf','question', 'target','candidate' ]\n",
        "feature_train = train.drop(cols_to_drop, axis=1, errors='ignore')\n",
        "y_train = train['target'].values\n",
        "n_features = feature_train.shape[1]\n",
        "\n",
        "# set model config and Kfold\n",
        "lgb_params = {\n",
        "    'boosting_type': 'gbdt',\n",
        "    'objective': 'binary',\n",
        "    'metric': 'binary_logloss',\n",
        "    'num_iterations ': 200,\n",
        "    'max_depth': 7,\n",
        "    'num_leaves': 80,\n",
        "    'learning_rate': 0.01, \n",
        "    'feature_fraction': 0.8,\n",
        "    'bagging_fraction': 0.8,\n",
        "    'bagging_freq': 5,\n",
        "    'xgboost_dart_mode': True,\n",
        "    'verbose': -1, \n",
        "    'is_unbalance': False,\n",
        "    'num_threads': 5\n",
        "}\n",
        "\n",
        "feature_names = list(feature_train.columns) \n",
        "\n",
        "lgb_train = lgb.Dataset(\n",
        "    feature_train, \n",
        "    y_train, \n",
        "    feature_name=feature_names,\n",
        "    )\n",
        "# lgb_train.raw_data = None\n",
        "\n",
        "\n",
        "model = lgb.train(\n",
        "    lgb_params,\n",
        "    lgb_train,\n",
        "    num_boost_round=1500\n",
        ")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 111
        },
        "id": "KatfUodIICrq",
        "outputId": "fee209bf-2876-482a-d8a8-928a3a2141be"
      },
      "source": [
        "feature_valid.head(2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>token_sort_ratio</th>\n",
              "      <th>token_set_ratio</th>\n",
              "      <th>cos_d</th>\n",
              "      <th>euc_d</th>\n",
              "      <th>lev_d</th>\n",
              "      <th>lev_r</th>\n",
              "      <th>jar_s</th>\n",
              "      <th>jaw_s</th>\n",
              "      <th>tfidf_score</th>\n",
              "      <th>question_tfidf_sum</th>\n",
              "      <th>answer_tfidf_sum</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>4.0</td>\n",
              "      <td>43.0</td>\n",
              "      <td>0.986270</td>\n",
              "      <td>1.404471</td>\n",
              "      <td>2650.0</td>\n",
              "      <td>0.027166</td>\n",
              "      <td>0.397897</td>\n",
              "      <td>0.397897</td>\n",
              "      <td>0.013730</td>\n",
              "      <td>2.828427</td>\n",
              "      <td>2.009709</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>12.0</td>\n",
              "      <td>60.0</td>\n",
              "      <td>0.685515</td>\n",
              "      <td>1.170910</td>\n",
              "      <td>613.0</td>\n",
              "      <td>0.107715</td>\n",
              "      <td>0.411379</td>\n",
              "      <td>0.411379</td>\n",
              "      <td>0.314485</td>\n",
              "      <td>2.828427</td>\n",
              "      <td>7.412493</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   token_sort_ratio  token_set_ratio  ...  question_tfidf_sum  answer_tfidf_sum\n",
              "0               4.0             43.0  ...            2.828427          2.009709\n",
              "1              12.0             60.0  ...            2.828427          7.412493\n",
              "\n",
              "[2 rows x 11 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iNAyU2WMxRnd"
      },
      "source": [
        "### Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7SCU1HX_Kxpm",
        "outputId": "87e11a2d-0a1f-4ab2-b7e1-094a2c7369d7"
      },
      "source": [
        "# 1/pred_df.groupby(level='example_id')['candidate'].count().mean()\n",
        "\n",
        "pred_df.groupby(level='example_id')['candidate'].count().mean()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "31.210526315789473"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VuYlT9zxxH_k",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 315
        },
        "outputId": "7a2b4699-ec07-4c0d-9dad-449225799ffb"
      },
      "source": [
        "cols_to_drop = ['example_id','document', 'Q_tfidf','C_tfidf','target','question','candidate' ]\n",
        "feature_valid = valid.drop(cols_to_drop, axis=1, errors='ignore')\n",
        "y_valid = valid['target'].values\n",
        "n_features = feature_valid.shape[1]\n",
        "\n",
        "# model predict\n",
        "p = model.predict(feature_valid,num_iteration=model.best_iteration)\n",
        "valid['pred'] = p\n",
        "\n",
        "max_pred = valid.groupby(['example_id'])['pred'].transform('max')\n",
        "valid['pred_target'] = np.where(valid['pred'].eq(max_pred), 1,0)\n",
        "\n",
        "pred_df = valid.groupby('example_id').apply(lambda x: x.sort_values(['pred_target'],ascending=False))\n",
        "pred_df = pred_df[['example_id','target','question','pred_target','pred','candidate']]\n",
        "\n",
        "print('Baseline f1 score ',1/pred_df.groupby(level='example_id')['candidate'].count().mean())\n",
        "\n",
        "prediction = pred_df.pred_target.values\n",
        "actual = pred_df.target.values\n",
        "f1_scor = f1_score(actual, prediction,average=None)\n",
        "# recall_scor = recall_score(actual, prediction,average=None)\n",
        "\n",
        "data = {'y_Actual':actual,'y_Predicted': prediction }\n",
        "df_result = pd.DataFrame(data, columns=['y_Actual','y_Predicted'])\n",
        "confusion_matrix = pd.crosstab(df_result['y_Actual'], df_result['y_Predicted'], rownames=['Actual'], colnames=['Predicted'])\n",
        "sns.heatmap(confusion_matrix, annot=True,fmt=\"d\")\n",
        "\n",
        "plt.show()\n",
        "\n",
        "print('Model f1_score: {}'.format(f1_scor))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Baseline f1 score  0.03204047217537943\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Model f1_score: [0.97212544 0.15789474]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "spyCtvPVL7tt"
      },
      "source": [
        "pd.set_option('display.max_colwidth', 100)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "vXgycKB2MH6m",
        "outputId": "55170b4f-a550-456d-9538-1386d6ba7c3c"
      },
      "source": [
        "pred_df=pred_df.drop('example_id', axis=1, errors='ignore').reset_index()\n",
        "pred_df[['question',\t'pred_target',\t'pred',\t'candidate']]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>question</th>\n",
              "      <th>pred_target</th>\n",
              "      <th>pred</th>\n",
              "      <th>candidate</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>who is the prime minister of republic of mauritius</td>\n",
              "      <td>1</td>\n",
              "      <td>0.609243</td>\n",
              "      <td>&lt;P&gt; The current Prime Minister of Mauritius , Pravind Jugnauth , leader of the MSM , was appoint...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>who is the prime minister of republic of mauritius</td>\n",
              "      <td>0</td>\n",
              "      <td>0.025688</td>\n",
              "      <td>&lt;Table&gt; &lt;Tr&gt; &lt;Th_colspan=\"2\"&gt; Prime Minister of Mauritius &lt;/Th&gt; &lt;/Tr&gt; &lt;Tr&gt; &lt;Td_colspan=\"2\"&gt; Coat...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>who is the prime minister of republic of mauritius</td>\n",
              "      <td>0</td>\n",
              "      <td>0.021371</td>\n",
              "      <td>&lt;P&gt; After the country became a Republic on 12 March 1992 , the President became the Head of Stat...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>who is the prime minister of republic of mauritius</td>\n",
              "      <td>0</td>\n",
              "      <td>0.000715</td>\n",
              "      <td>&lt;P&gt; According to the third Schedule of the Constitution of Mauritius , an oath under this sectio...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>who is the prime minister of republic of mauritius</td>\n",
              "      <td>0</td>\n",
              "      <td>0.064634</td>\n",
              "      <td>&lt;P&gt; On 12 March 1992 , Mauritius became a Republic State , with a new constitution in 1992 , the...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>588</th>\n",
              "      <td>when were the plus and minus signs first recorded</td>\n",
              "      <td>0</td>\n",
              "      <td>0.000592</td>\n",
              "      <td>&lt;P&gt; In mathematics and most programming languages , the rules for the order of operations mean t...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>589</th>\n",
              "      <td>when were the plus and minus signs first recorded</td>\n",
              "      <td>0</td>\n",
              "      <td>0.000013</td>\n",
              "      <td>&lt;P&gt; Some elementary teachers use raised plus and minus signs before numbers to show they are pos...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>590</th>\n",
              "      <td>when were the plus and minus signs first recorded</td>\n",
              "      <td>0</td>\n",
              "      <td>0.000015</td>\n",
              "      <td>&lt;Dl&gt; &lt;Dd&gt; 3 − 5 becomes 3 + 5 = 8 , &lt;/Dd&gt; &lt;/Dl&gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>591</th>\n",
              "      <td>when were the plus and minus signs first recorded</td>\n",
              "      <td>0</td>\n",
              "      <td>0.000015</td>\n",
              "      <td>&lt;P&gt; or even as &lt;/P&gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>592</th>\n",
              "      <td>when were the plus and minus signs first recorded</td>\n",
              "      <td>0</td>\n",
              "      <td>0.000025</td>\n",
              "      <td>&lt;P&gt; A Jewish tradition that dates from at least the 19th century is to write plus using a symbol...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>593 rows × 4 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                               question  ...                                                                                            candidate\n",
              "0    who is the prime minister of republic of mauritius  ...  <P> The current Prime Minister of Mauritius , Pravind Jugnauth , leader of the MSM , was appoint...\n",
              "1    who is the prime minister of republic of mauritius  ...  <Table> <Tr> <Th_colspan=\"2\"> Prime Minister of Mauritius </Th> </Tr> <Tr> <Td_colspan=\"2\"> Coat...\n",
              "2    who is the prime minister of republic of mauritius  ...  <P> After the country became a Republic on 12 March 1992 , the President became the Head of Stat...\n",
              "3    who is the prime minister of republic of mauritius  ...  <P> According to the third Schedule of the Constitution of Mauritius , an oath under this sectio...\n",
              "4    who is the prime minister of republic of mauritius  ...  <P> On 12 March 1992 , Mauritius became a Republic State , with a new constitution in 1992 , the...\n",
              "..                                                  ...  ...                                                                                                  ...\n",
              "588   when were the plus and minus signs first recorded  ...  <P> In mathematics and most programming languages , the rules for the order of operations mean t...\n",
              "589   when were the plus and minus signs first recorded  ...  <P> Some elementary teachers use raised plus and minus signs before numbers to show they are pos...\n",
              "590   when were the plus and minus signs first recorded  ...                                                      <Dl> <Dd> 3 − 5 becomes 3 + 5 = 8 , </Dd> </Dl>\n",
              "591   when were the plus and minus signs first recorded  ...                                                                                  <P> or even as </P>\n",
              "592   when were the plus and minus signs first recorded  ...  <P> A Jewish tradition that dates from at least the 19th century is to write plus using a symbol...\n",
              "\n",
              "[593 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nY00uumqb6uc"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}